{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "OpenCV_HOG+SVM_Face_Detection.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "WWoNtQz0eK6W",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Face Detection using HOG+SVM:\n",
        "In this example, we will take a look at one such feature extraction technique, the [Histogram of Oriented Gradients](https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients) (HOG), which transforms image pixels into a vector representation that is sensitive to broadly informative image features regardless of confounding factors like illumination.\n",
        "We will use these features together with SVM to develop a simple face detector. \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "87vMbb3xKFNo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns; sns.set()\n",
        "import numpy as np\n",
        "from skimage import data, color, feature\n",
        "import skimage.data\n",
        "\n",
        "image = color.rgb2gray(data.chelsea())\n",
        "print(image.shape)\n",
        "hog_vec, hog_vis = feature.hog(image, visualise=True)\n",
        "\n",
        "fig, ax = plt.subplots(1, 2, figsize=(12, 6), subplot_kw=dict(xticks=[], yticks=[]))\n",
        "ax[0].imshow(image, cmap='gray')\n",
        "ax[0].set_title('input image')\n",
        "\n",
        "ax[1].imshow(hog_vis)\n",
        "ax[1].set_title('visualization of HOG features');"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iz3jnnCVd6Ou",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 1. Obtain a set of positive training samples\n",
        "\n",
        "Let's start by finding some positive training samples that show a variety of faces.\n",
        "We have one easy set of data to work withâ€”the Labeled Faces in the Wild dataset, which can be downloaded by Scikit-Learn:"
      ]
    },
    {
      "metadata": {
        "id": "fsva4_gMKYiw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_lfw_people\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# download label faces in the wild dataset\n",
        "faces = fetch_lfw_people()\n",
        "positive_patches = faces.images\n",
        "positive_patches.shape # (13233,62,47) where each image is with size 47*62 (W*H)\n",
        "#cv2_imshow(positive_patches[0])\n",
        "\n",
        "# show postive images\n",
        "fig, ax = plt.subplots(6, 10)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(positive_patches[50 * i], cmap='gray')\n",
        "    axi.axis('off')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O02sDjXsX7tg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**2. Obtain a set of negative training samples** <br>\n",
        "Next we need a set of similarly sized thumbnails which do not have a face in them. One way to do this is to take any corpus of input images, and extract thumbnails from them at a variety of scales. Here we can use some of the images (The USC-SIPI Image Database) shipped with Scikit-Image, along with Scikit-Learn's PatchExtractor: "
      ]
    },
    {
      "metadata": {
        "id": "Abzhr72pK1t2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from skimage import data, transform\n",
        "\n",
        "\n",
        "imgs_to_use = ['camera', 'text', 'coins', 'moon',\n",
        "               'page', 'clock', 'immunohistochemistry',\n",
        "               'chelsea', 'coffee', 'hubble_deep_field']\n",
        "# download negative image sources: no faces inside each image\n",
        "# the image size is 512*512\n",
        "images = [color.rgb2gray(getattr(data, name)())\n",
        "          for name in imgs_to_use]\n",
        "\n",
        "from sklearn.feature_extraction.image import PatchExtractor\n",
        "\n",
        "def extract_patches(img, N, scale=1.0, patch_size=positive_patches[0].shape):\n",
        "    # patches are cropped with the postive training image size mulitplied with scale factor\n",
        "    extracted_patch_size = tuple((scale * np.array(patch_size)).astype(int))\n",
        "    extractor = PatchExtractor(patch_size=extracted_patch_size,\n",
        "                               max_patches=N, random_state=0)\n",
        "   \n",
        "    # transform the image (1*H*W) to designated size 62*47*scale\n",
        "    patches = extractor.transform(img[np.newaxis])   \n",
        "    # rescale to the same size if patches are cropped with scale other than 1\n",
        "    if scale != 1:\n",
        "        patches = np.array([transform.resize(patch, patch_size)\n",
        "                            for patch in patches])\n",
        "    return patches\n",
        "\n",
        "# horizontally concatenate images originally cropped with different scales\n",
        "# images come from 10 classes (images), each of which will be cropped with 3 different scales\n",
        "# Totally images 1000*3*10 = 30000\n",
        "negative_patches = np.vstack([extract_patches(im, 1000, scale)\n",
        "                              for im in images for scale in [0.5, 1.0, 2.0]])\n",
        "negative_patches.shape\n",
        "\n",
        "# show cropped negative training images\n",
        "fig, ax = plt.subplots(6, 10)\n",
        "for i, axi in enumerate(ax.flat):\n",
        "    axi.imshow(negative_patches[500 * i], cmap='gray')\n",
        "    axi.axis('off')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fqoWt1VGXtfL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 3. Perform training and load testing image:"
      ]
    },
    {
      "metadata": {
        "id": "GWH_tgNjL5Hw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# giving labels for postive and negative images\n",
        "from itertools import chain\n",
        "\n",
        "# hog size: blocks: 3*3; pixels in each block: 8; stride=1 block; bins for each block=9\n",
        "# total blocks: floor((62-24)/8)+1=5; floor((47-24)/8)+1=3\n",
        "# total feature size = 5*3*9*9 = 1215\n",
        "X_train = np.array([feature.hog(im)\n",
        "                    for im in chain(positive_patches,\n",
        "                                    negative_patches)])\n",
        "\n",
        "#print(X_train.shape)\n",
        "y_train = np.zeros(X_train.shape[0])\n",
        "# top images are positive training data so their label will be set to 1\n",
        "y_train[:positive_patches.shape[0]] = 1\n",
        "\n",
        "# performing (SVM) classifier training\n",
        "from sklearn.svm import LinearSVC\n",
        "#from sklearn.grid_search import GridSearchCV\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# brute-force for all hyper parameters in training SVM\n",
        "grid = GridSearchCV(LinearSVC(), {'C': [1.0, 2.0, 4.0, 8.0]})\n",
        "grid.fit(X_train, y_train)\n",
        "grid.best_score_\n",
        "model = grid.best_estimator_\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# show and crop test image\n",
        "test_image = skimage.data.astronaut()\n",
        "test_image = skimage.color.rgb2gray(test_image)\n",
        "test_image = skimage.transform.rescale(test_image, 0.5)\n",
        "test_image = test_image[:160, 40:180]\n",
        "\n",
        "plt.imshow(test_image, cmap='gray')\n",
        "plt.axis('off');\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LsZAWt0BfLpt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### 4. Perform detection by iteratively cropping images and classifying them:"
      ]
    },
    {
      "metadata": {
        "id": "Y8wRPSm3qaI5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# crop images in sliding window fasion\n",
        "def sliding_window(img, patch_size=positive_patches[0].shape,\n",
        "                   istep=2, jstep=2, scale=1.0):\n",
        "    Ni, Nj = (int(scale * s) for s in patch_size)\n",
        "    for i in range(0, img.shape[0] - Ni, istep):\n",
        "        for j in range(0, img.shape[1] - Ni, jstep):\n",
        "            patch = img[i:i + Ni, j:j + Nj]\n",
        "            if scale != 1:\n",
        "                patch = transform.resize(patch, patch_size)\n",
        "            yield (i, j), patch\n",
        "            \n",
        "indices, patches = zip(*sliding_window(test_image))\n",
        "patches_hog = np.array([feature.hog(patch) for patch in patches])\n",
        "#patches_hog.shape\n",
        "\n",
        "# perform classification\n",
        "labels = model.predict(patches_hog)\n",
        "#prob = model.predict_proba(patches_hog)\n",
        "#print(prob)\n",
        "labels.sum()\n",
        "\n",
        "# overlapping bounding boxes on the test images\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(test_image, cmap='gray')\n",
        "ax.axis('off')\n",
        "\n",
        "Ni, Nj = positive_patches[0].shape\n",
        "indices = np.array(indices)\n",
        "\n",
        "# get the size of the result\n",
        "numBBox, _ = indices[labels == 1].shape\n",
        "\n",
        "# initialize the numpy array to store x_top_left,y_top_right,x_btm_right,y_btm_right\n",
        "BBox_array = np.zeros((numBBox,4))\n",
        "\n",
        "#print(numBBox)\n",
        "\n",
        "running_index = 0\n",
        "\n",
        "# overlapping bounding boxes as well as store raw detection results\n",
        "for i, j in indices[labels == 1]:\n",
        "    #print(i,j)\n",
        "    BBox_array.itemset((running_index,0),j) \n",
        "    BBox_array.itemset((running_index,1),i) \n",
        "    BBox_array.itemset((running_index,2),j+Nj) \n",
        "    BBox_array.itemset((running_index,3),i+Ni) \n",
        "    running_index = running_index + 1 \n",
        "        \n",
        "    ax.add_patch(plt.Rectangle((j, i), Nj, Ni, edgecolor='red',\n",
        "                               alpha=0.3, lw=2, facecolor='none'))\n",
        "    \n",
        "#print(BBox_array)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "x_vZPSYWfsaT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "***5. Apply Non-Maximal-Suppression for eliminating multiple/redundant outputs:**"
      ]
    },
    {
      "metadata": {
        "id": "0tprkv3aqpnY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# do non-maximal-suppression for producing the only output bounding box\n",
        "def non_max_suppression_fast(boxes, overlapThresh):\n",
        "\t# if there are no boxes, return an empty list\n",
        "\tif len(boxes) == 0:\n",
        "\t\treturn []\n",
        " \n",
        "\t# if the bounding boxes integers, convert them to floats --\n",
        "\t# this is important since we'll be doing a bunch of divisions\n",
        "\tif boxes.dtype.kind == \"i\":\n",
        "\t\tboxes = boxes.astype(\"float\")\n",
        " \n",
        "\t# initialize the list of picked indexes\t\n",
        "\tpick = []\n",
        " \n",
        "\t# grab the coordinates of the bounding boxes\n",
        "\tx1 = boxes[:,0]\n",
        "\ty1 = boxes[:,1]\n",
        "\tx2 = boxes[:,2]\n",
        "\ty2 = boxes[:,3]\n",
        " \n",
        "\t# compute the area of the bounding boxes and sort the bounding\n",
        "\t# boxes by the bottom-right y-coordinate of the bounding box\n",
        "\tarea = (x2 - x1 + 1) * (y2 - y1 + 1)\n",
        "\tidxs = np.argsort(y2)\n",
        " \n",
        "\t# keep looping while some indexes still remain in the indexes\n",
        "\t# list\n",
        "\twhile len(idxs) > 0:\n",
        "\t\t# grab the last index in the indexes list and add the\n",
        "\t\t# index value to the list of picked indexes\n",
        "\t\tlast = len(idxs) - 1\n",
        "\t\ti = idxs[last]\n",
        "\t\tpick.append(i)\n",
        " \n",
        "\t\t# find the largest (x, y) coordinates for the start of\n",
        "\t\t# the bounding box and the smallest (x, y) coordinates\n",
        "\t\t# for the end of the bounding box\n",
        "\t\txx1 = np.maximum(x1[i], x1[idxs[:last]])\n",
        "\t\tyy1 = np.maximum(y1[i], y1[idxs[:last]])\n",
        "\t\txx2 = np.minimum(x2[i], x2[idxs[:last]])\n",
        "\t\tyy2 = np.minimum(y2[i], y2[idxs[:last]])\n",
        " \n",
        "\t\t# compute the width and height of the bounding box\n",
        "\t\tw = np.maximum(0, xx2 - xx1 + 1)\n",
        "\t\th = np.maximum(0, yy2 - yy1 + 1)\n",
        " \n",
        "\t\t# compute the ratio of overlap\n",
        "\t\toverlap = (w * h) / area[idxs[:last]]\n",
        " \n",
        "\t\t# delete all indexes from the index list that have\n",
        "\t\tidxs = np.delete(idxs, np.concatenate(([last],\n",
        "\t\t\tnp.where(overlap > overlapThresh)[0])))\n",
        " \n",
        "\t# return only the bounding boxes that were picked using the\n",
        "\t# integer data type\n",
        "\treturn boxes[pick].astype(\"int\")\n",
        "\n",
        "# doing non-maxmal suppression to eliminate redundant bbox\n",
        "NMS_result = non_max_suppression_fast(BBox_array,0.5)\n",
        "\n",
        "# fetch the number of remained bounding box\n",
        "NMS_result_num, _ = NMS_result.shape\n",
        "\n",
        "#print(NMS_result)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.imshow(test_image, cmap='gray')\n",
        "ax.axis('off')\n",
        "\n",
        "for i in range(NMS_result_num):\n",
        "        \n",
        "    x = NMS_result[i,0]\n",
        "    y = NMS_result[i,1]\n",
        "    w = NMS_result[i,2] - NMS_result[i,0]\n",
        "    h = NMS_result[i,3] - NMS_result[i,1]\n",
        "    ax.add_patch(plt.Rectangle((x, y), w, h, edgecolor='red',\n",
        "                               linewidth=5, lw=2, facecolor='none'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}